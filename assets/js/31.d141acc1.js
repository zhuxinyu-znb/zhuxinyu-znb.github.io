(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{230:function(t,s,e){"use strict";e.r(s);var r=e(0),a=Object(r.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("ul",[e("li",[t._v("content\n{:toc}")])]),t._v(" "),e("h3",{attrs:{id:"爬虫系统以及robots协议介绍"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#爬虫系统以及robots协议介绍"}},[t._v("#")]),t._v(" 爬虫系统以及Robots协议介绍")]),t._v(" "),e("p",[t._v("爬虫，是一中自动获取网页内容的程序。是搜索引擎的重要组成部分，因此搜索引擎优化很大程度上就是针对爬虫而做出优化。\nrobots.txt 是一个文本文件，robots.txt是一个协议，不是一个命令。robots.txt是爬虫要查看的第一个文件。robots.txt文件告诉爬虫在服务器上什么文件是可以被查看的，搜索机器人就会按照该文件中的内容来确定访问的范围。")]),t._v(" "),e("h3",{attrs:{id:"配置爬虫系统和开发环境"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#配置爬虫系统和开发环境"}},[t._v("#")]),t._v(" 配置爬虫系统和开发环境")]),t._v(" "),e("p",[t._v("直接使用express脚手架创建项目\n安装 request 安装 cheerio")]),t._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("npm install request cheerio --save-dev\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br")])]),e("p",[t._v("未完待续。。")])])}),[],!1,null,null,null);s.default=a.exports}}]);